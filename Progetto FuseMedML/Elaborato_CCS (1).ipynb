{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Elaborato_CCS.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5c3270c3c6884c3db7f38b01de3fff38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b513a36dd4b94961918743bbc6363c14",
              "IPY_MODEL_0fdb873ad7f643718a6c81b0609b0223",
              "IPY_MODEL_9f94a71585db4d7cb26c5a7a7f2fb60c"
            ],
            "layout": "IPY_MODEL_4d812f7157c04c51a0b7c96127624d74"
          }
        },
        "b513a36dd4b94961918743bbc6363c14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e62aa23d65c842f3ba5b1ca8c4a13c79",
            "placeholder": "​",
            "style": "IPY_MODEL_5aca86ea9ab44d879a368e02e3128edf",
            "value": "100%"
          }
        },
        "0fdb873ad7f643718a6c81b0609b0223": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_441385cdc14b4dbbbef9a0150ce4d168",
            "max": 531460341,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7fc4022727b14eceb01b19c5400f4f86",
            "value": 531460341
          }
        },
        "9f94a71585db4d7cb26c5a7a7f2fb60c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_292625d90de342199985d8231a101587",
            "placeholder": "​",
            "style": "IPY_MODEL_91a3a978bd68403ba4fb114979bb523e",
            "value": " 507M/507M [00:10&lt;00:00, 60.7MB/s]"
          }
        },
        "4d812f7157c04c51a0b7c96127624d74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e62aa23d65c842f3ba5b1ca8c4a13c79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5aca86ea9ab44d879a368e02e3128edf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "441385cdc14b4dbbbef9a0150ce4d168": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fc4022727b14eceb01b19c5400f4f86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "292625d90de342199985d8231a101587": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91a3a978bd68403ba4fb114979bb523e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Sistema di riconoscimento visivo tramite FuseMedML**\n",
        "\n"
      ],
      "metadata": {
        "id": "FWSD4jym-5OX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Fase di settaggio dell'ambiente**"
      ],
      "metadata": {
        "id": "QmBqPO6TsRwx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Montaggio delle cartelle di Google Drive"
      ],
      "metadata": {
        "id": "vsyQm52AsYv8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "McoYvQ1REndr",
        "outputId": "ed6a74bf-2251-4edb-9bd1-2bdfb12fe29e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Clonazione e installazione della libreria FuseMedML"
      ],
      "metadata": {
        "id": "WjuaM_FZ_Pzf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/IBM/fuse-med-ml.git     #clonazione della repository delle funzioni di fuse\n",
        "%cd fuse-med-ml                                       \n",
        "!pip install -e .                                     #aggiornamento delle dipendenze pip per l'elaborazione delle funzioni"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "N9dPIH3hWSC6",
        "outputId": "1b7acdc0-6fc0-435d-8119-05a9b6ef27de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'fuse-med-ml'...\n",
            "remote: Enumerating objects: 3915, done.\u001b[K\n",
            "remote: Counting objects: 100% (1154/1154), done.\u001b[K\n",
            "remote: Compressing objects: 100% (603/603), done.\u001b[K\n",
            "remote: Total 3915 (delta 607), reused 1011 (delta 533), pack-reused 2761\u001b[K\n",
            "Receiving objects: 100% (3915/3915), 74.59 MiB | 36.18 MiB/s, done.\n",
            "Resolving deltas: 100% (2231/2231), done.\n",
            "/content/fuse-med-ml\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Obtaining file:///content/fuse-med-ml\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.7/dist-packages (from fuse-med-ml==0.1.12) (1.21.6)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.7/dist-packages (from fuse-med-ml==0.1.12) (1.3.5)\n",
            "Requirement already satisfied: tqdm>=4.52.0 in /usr/local/lib/python3.7/dist-packages (from fuse-med-ml==0.1.12) (4.64.0)\n",
            "Collecting scipy>=1.5.4\n",
            "  Downloading scipy-1.7.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 38.1 MB 1.3 MB/s \n",
            "\u001b[?25hCollecting matplotlib>=3.3.3\n",
            "  Downloading matplotlib-3.5.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.2 MB 50.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-image>=0.17.2 in /usr/local/lib/python3.7/dist-packages (from fuse-med-ml==0.1.12) (0.18.3)\n",
            "Requirement already satisfied: scikit-learn>=0.23.2 in /usr/local/lib/python3.7/dist-packages (from fuse-med-ml==0.1.12) (1.0.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from fuse-med-ml==0.1.12) (1.1.0)\n",
            "Requirement already satisfied: torch>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from fuse-med-ml==0.1.12) (1.11.0+cu113)\n",
            "Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from fuse-med-ml==0.1.12) (0.12.0+cu113)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from fuse-med-ml==0.1.12) (2.8.0)\n",
            "Collecting SimpleITK>=1.2.0\n",
            "  Downloading SimpleITK-2.1.1.2-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (48.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 48.4 MB 19 kB/s \n",
            "\u001b[?25hCollecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "Requirement already satisfied: opencv-python<=4.3.0.36 in /usr/local/lib/python3.7/dist-packages (from fuse-med-ml==0.1.12) (4.1.2.30)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from fuse-med-ml==0.1.12) (5.5.0)\n",
            "Collecting pydicom\n",
            "  Downloading pydicom-2.3.0-py3-none-any.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 44.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from fuse-med-ml==0.1.12) (3.1.0)\n",
            "Collecting hdf5plugin\n",
            "  Downloading hdf5plugin-3.3.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.7 MB 28.0 MB/s \n",
            "\u001b[?25hCollecting deepdiff\n",
            "  Downloading deepdiff-5.8.1-py3-none-any.whl (69 kB)\n",
            "\u001b[K     |████████████████████████████████| 69 kB 9.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: statsmodels in /usr/local/lib/python3.7/dist-packages (from fuse-med-ml==0.1.12) (0.10.2)\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.7/dist-packages (from fuse-med-ml==0.1.12) (3.0.2)\n",
            "Requirement already satisfied: pycocotools>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from fuse-med-ml==0.1.12) (2.0.4)\n",
            "Collecting xmlrunner\n",
            "  Downloading xmlrunner-1.7.7.tar.gz (5.6 kB)\n",
            "Collecting paramiko\n",
            "  Downloading paramiko-2.11.0-py2.py3-none-any.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 59.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tables in /usr/local/lib/python3.7/dist-packages (from fuse-med-ml==0.1.12) (3.7.0)\n",
            "Collecting fonttools>=4.22.0\n",
            "  Downloading fonttools-4.33.3-py3-none-any.whl (930 kB)\n",
            "\u001b[K     |████████████████████████████████| 930 kB 57.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.3.3->fuse-med-ml==0.1.12) (0.11.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.3.3->fuse-med-ml==0.1.12) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.3.3->fuse-med-ml==0.1.12) (2.8.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.3.3->fuse-med-ml==0.1.12) (7.1.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.3.3->fuse-med-ml==0.1.12) (21.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.3.3->fuse-med-ml==0.1.12) (1.4.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib>=3.3.3->fuse-med-ml==0.1.12) (4.2.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2->fuse-med-ml==0.1.12) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.3->fuse-med-ml==0.1.12) (1.15.0)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.17.2->fuse-med-ml==0.1.12) (2021.11.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.17.2->fuse-med-ml==0.1.12) (2.4.1)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.17.2->fuse-med-ml==0.1.12) (1.3.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.17.2->fuse-med-ml==0.1.12) (2.6.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.23.2->fuse-med-ml==0.1.12) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.23.2->fuse-med-ml==0.1.12) (1.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.8.1->fuse-med-ml==0.1.12) (2.23.0)\n",
            "Collecting ordered-set<4.2.0,>=4.1.0\n",
            "  Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->fuse-med-ml==0.1.12) (1.5.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->fuse-med-ml==0.1.12) (57.4.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->fuse-med-ml==0.1.12) (4.4.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->fuse-med-ml==0.1.12) (2.6.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->fuse-med-ml==0.1.12) (0.7.5)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->fuse-med-ml==0.1.12) (4.8.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->fuse-med-ml==0.1.12) (1.0.18)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->fuse-med-ml==0.1.12) (5.1.1)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->fuse-med-ml==0.1.12) (0.8.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->fuse-med-ml==0.1.12) (0.2.5)\n",
            "Collecting pynacl>=1.0.1\n",
            "  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\n",
            "\u001b[K     |████████████████████████████████| 856 kB 57.2 MB/s \n",
            "\u001b[?25hCollecting bcrypt>=3.1.3\n",
            "  Downloading bcrypt-3.2.2-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.3 MB/s \n",
            "\u001b[?25hCollecting cryptography>=2.5\n",
            "  Downloading cryptography-37.0.2-cp36-abi3-manylinux_2_24_x86_64.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 30.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.1 in /usr/local/lib/python3.7/dist-packages (from bcrypt>=3.1.3->paramiko->fuse-med-ml==0.1.12) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.1->bcrypt>=3.1.3->paramiko->fuse-med-ml==0.1.12) (2.21)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->fuse-med-ml==0.1.12) (0.7.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.8.1->fuse-med-ml==0.1.12) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.8.1->fuse-med-ml==0.1.12) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.8.1->fuse-med-ml==0.1.12) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.8.1->fuse-med-ml==0.1.12) (2022.5.18.1)\n",
            "Requirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from statsmodels->fuse-med-ml==0.1.12) (0.5.2)\n",
            "Requirement already satisfied: numexpr>=2.6.2 in /usr/local/lib/python3.7/dist-packages (from tables->fuse-med-ml==0.1.12) (2.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->fuse-med-ml==0.1.12) (0.6.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->fuse-med-ml==0.1.12) (1.0.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->fuse-med-ml==0.1.12) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->fuse-med-ml==0.1.12) (1.8.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->fuse-med-ml==0.1.12) (3.17.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->fuse-med-ml==0.1.12) (3.3.7)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->fuse-med-ml==0.1.12) (0.37.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->fuse-med-ml==0.1.12) (1.35.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->fuse-med-ml==0.1.12) (1.46.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->fuse-med-ml==0.1.12) (0.4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->fuse-med-ml==0.1.12) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->fuse-med-ml==0.1.12) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->fuse-med-ml==0.1.12) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->fuse-med-ml==0.1.12) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->fuse-med-ml==0.1.12) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->fuse-med-ml==0.1.12) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->fuse-med-ml==0.1.12) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->fuse-med-ml==0.1.12) (3.2.0)\n",
            "Building wheels for collected packages: wget, xmlrunner\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9675 sha256=03e20179f6fad09f82a2b227591516269f37e0c720feb7853246a1825eeff04a\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/b6/7c/0e63e34eb06634181c63adacca38b79ff8f35c37e3c13e3c02\n",
            "  Building wheel for xmlrunner (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for xmlrunner: filename=xmlrunner-1.7.7-py3-none-any.whl size=6233 sha256=8c1d22b6cf78d2111305095a7088386ce5a06144f6411dd02a447256e25ebc13\n",
            "  Stored in directory: /root/.cache/pip/wheels/bb/ae/64/7394a8365bd8e7bf4c49b01d80c0260d1c1ec975183ac1ce37\n",
            "Successfully built wget xmlrunner\n",
            "Installing collected packages: fonttools, scipy, pynacl, ordered-set, matplotlib, cryptography, bcrypt, xmlrunner, wget, SimpleITK, pydicom, paramiko, hdf5plugin, deepdiff, fuse-med-ml\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "  Running setup.py develop for fuse-med-ml\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed SimpleITK-2.1.1.2 bcrypt-3.2.2 cryptography-37.0.2 deepdiff-5.8.1 fonttools-4.33.3 fuse-med-ml-0.1.12 hdf5plugin-3.3.0 matplotlib-3.5.2 ordered-set-4.1.0 paramiko-2.11.0 pydicom-2.3.0 pynacl-1.5.0 scipy-1.7.3 wget-3.2 xmlrunner-1.7.7\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import di Librerie Python e Fuse"
      ],
      "metadata": {
        "id": "p4UfFBuQ-z8B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from typing import OrderedDict\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "from torchvision import transforms, datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from fuse.eval.evaluator import EvaluatorDefault\n",
        "from fuse.data.dataset.dataset_wrapper import FuseDatasetWrapper\n",
        "from fuse.data.sampler.sampler_balanced_batch import FuseSamplerBalancedBatch\n",
        "from fuse.losses.loss_default import FuseLossDefault\n",
        "from fuse.managers.callbacks.callback_tensorboard import FuseTensorboardCallback\n",
        "from fuse.managers.manager_default import FuseManagerDefault\n",
        "from fuse.eval.metrics.classification.metrics_classification_common import MetricAccuracy, MetricAUCROC, MetricROCCurve, MetricAUCPR, MetricConfusionMatrix, MetricBSS\n",
        "from fuse.eval.metrics.classification.metrics_thresholding_common import MetricApplyThresholds\n",
        "from fuse.models.model_wrapper import FuseModelWrapper\n",
        "from fuse_examples.tutorials.hello_world.hello_world_utils import LeNet, perform_softmax\n",
        "from fuse.data.augmentor.augmentor_toolbox import aug_image_default_pipeline"
      ],
      "metadata": {
        "id": "bEvx-onf-j5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Definizione dei path di output\n"
      ],
      "metadata": {
        "id": "XPbZ57f2BwSJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ROOT = 'CCS' # Cartella che conterrà tutti i file necessari al funzionamento della rete\n",
        "PATHS = {'model_dir': os.path.join(ROOT, 'T1VOL/model_dir'),\n",
        "         'force_reset_model_dir': True,  # Se impostato a True il path contenente il modello verrà ripristinato automaticamente - \n",
        "                                         # altrimenti è necessario ogni volta confermare l'operazione di ripristino tramite comando.\n",
        "         'cache_dir': os.path.join(ROOT, 'T1VOL/cache_dir'),\n",
        "         'inference_dir': os.path.join(ROOT, 'T1VOL/infer_dir'),\n",
        "         'eval_dir': os.path.join(ROOT, 'T1VOL/eval_dir')}\n",
        "\n",
        "paths = PATHS"
      ],
      "metadata": {
        "id": "UMPdkd3sByos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Fase di settaggio dei parametri di addestramento**"
      ],
      "metadata": {
        "id": "qrb0fQwts8q2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parametri generici di addestramento\n",
        "\n",
        "All'interno della libreria Fuse, è necessario settare alcune tipoligie obbligatorie di parametri, tra cui si possono distinguere tre differenti classi:\n",
        "* Parametri di tipo **Model** - che tipo di modello si utilizza.\n",
        "* Parametri di tipo **Data** - definisce i parametri per il preprocessing.\n",
        "* Parametri di tipo **Manager** - definisce i parametri per il training."
      ],
      "metadata": {
        "id": "jdWL2_52B31m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_COMMON_PARAMS = {}\n",
        "\n",
        "### Model ###\n",
        "TRAIN_COMMON_PARAMS['model'] = 'vgg11'                    #modello scelto: VGG11\n",
        "\n",
        "### Data ###\n",
        "TRAIN_COMMON_PARAMS['data.batch_size'] = 70               #dimensione di ogni batch\n",
        "TRAIN_COMMON_PARAMS['data.train_num_workers'] = 8         #numero di worker della rete durante il training\n",
        "TRAIN_COMMON_PARAMS['data.validation_num_workers'] = 8    #numero di worker della rete durante la validazione\n",
        "\n",
        "### Manager ###\n",
        "TRAIN_COMMON_PARAMS['manager.train_params'] = {\n",
        "    'device': 'cuda',                 # device, si prende la scheda video\n",
        "    'num_epochs': 40,                 # numero di epoche durante la fase di training\n",
        "    'virtual_batch_size': 1,          # numero di batch in un batch virtuale: in questo caso la mappatura è 1:1\n",
        "    'start_saving_epochs': 5,         # prima epoca da cui comincio a salvare i pesi\n",
        "    'gap_between_saving_epochs': 2,   # numero di epoche tra ogni checkpoint di pesi\n",
        "                                      # ogni 5 epoche salvo i pesi della rete, partendo dall'epoca n.10\n",
        "}\n",
        "TRAIN_COMMON_PARAMS['manager.best_epoch_source'] = {\n",
        "    'source': 'metrics.accuracy',     # si sceglie la metrica di valutazione dal dizionario 'epoch_result': in questo caso Accuracy\n",
        "    'optimization': 'max',            # si sceglie l'obiettivo per tale metrica, in questo caso si vuole massimizzare l'accuracy\n",
        "    'on_equal_values': 'better',      # si sceglie che cosa fare in corrispondenza di valori di accuracy uguali nella best epoch, \n",
        "                                      # in questo caso si prende la 'better', ma potevo scegliere anche 'worst'\n",
        "}\n",
        "TRAIN_COMMON_PARAMS['manager.learning_rate'] = 0.0001               #si definisce il learning rate\n",
        "TRAIN_COMMON_PARAMS['manager.weight_decay'] = 0.001                 #si definisce il decay dei pesi della rete\n",
        "TRAIN_COMMON_PARAMS['manager.resume_checkpoint_filename'] = None    # Messo a None prova a ripristinare il checkpoint\n",
        "\n",
        "TRAIN_COMMON_PARAMS['manager.train_params']['device'] = 'cuda'   # si sceglie il device su cui eseguire la rete\n",
        "\n",
        "train_params = TRAIN_COMMON_PARAMS"
      ],
      "metadata": {
        "id": "2CfbJnd4CGS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Dimensione virtuale dei batch"
      ],
      "metadata": {
        "id": "n9cJgM4NPnU-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Per i modelli le cui prestazioni sono limitate dalla memoria della GPU, e quindi dalla dimensione dei batch - molti modelli NLP, in particolare, hanno questo problema - questa semplice tecnica offre un modo semplice per ottenere una dimensione \"virtuale\" dei batch più grande di quella che si adatta alla memoria.\n",
        "Per esempio, se è possibile inserire solo 16 campioni per batch nella memoria della GPU, è possibile inoltrare due batch, poi passare all'indietro una volta, per una dimensione effettiva di 32 batch. Oppure passare avanti quattro volte, passare indietro una volta, per una dimensione del batch di 64. E così via.\n",
        "Questo è possibile impostarlo tramite fuse variando il parametro 'virtual_batch_size', che indica il numero di batch effettivi da includere all'interno di un batch virtuale"
      ],
      "metadata": {
        "id": "0Ahqv6FBPiE2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Decadimento dei pesi"
      ],
      "metadata": {
        "id": "PSKl5LtpRO0f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Il parametro 'weight_decay' serve a stabilire un coefficiente di penalità per il learning rate. Questo parametro viene aggiunto alla loss calcolata al passo precedente, moltiplicando tale fattore per la norma quadra dei pesi precedente. In sostanza, viene usata la formula:\n",
        "$$loss(i)=loss(i-1) + WD*||weights||^2$$"
      ],
      "metadata": {
        "id": "vJTjMwPhRRf-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Fase di processing dei dati**\n",
        "Si vanno a convertire in dataloaders tutti i dati presenti, sfruttanto la funzione di pytorch (`torch.utils.data.DataLoader`) sia per la parte di validation che per la parte di training usando i seguenti componenti Fuse:\n",
        "1. Wrapper - **FuseDatasetWrapper**:\n",
        "    Raccoglie il dataset convertito in DataLoader in un dizionario tale che sia mappato con le etichette date in input.\n",
        "2. Sampler - **FuseSamplerBalancedBatch**:\n",
        "    Implementa semplicemente il sampler di Pytorch 'torch.utils.data.sampler'. Tale sampler crea dei batch bilanciati tra le classi, comprendendo un uguale numero di samples per ogni classe all'interno del batch."
      ],
      "metadata": {
        "id": "5xohLaAJEOJ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([                        #si va a definire una trasformazione in tensori\n",
        "    transforms.Resize((224,224)),                       #si ridefinisce la dimensione dell'immagine\n",
        "    transforms.ToTensor(),                              #si attua la trasformazione in tensore\n",
        "    transforms.Normalize((0.1307,), (0.3081,))          #si applica una normalizzazione secondo dei pesi prefissati\n",
        "])"
      ],
      "metadata": {
        "id": "_ETrOPLSMU51"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install split-folders                                                                  #libreria per l'installazione della funzioni di split\n",
        "import splitfolders\n",
        "\n",
        "data_dir = '/content/drive/MyDrive/DATI/T1VOL'                                             #directory contenente i dati da partizionare\n",
        "splitfolders.ratio(data_dir, output=\"content/DATASET\", seed=1337, ratio=(.6, 0.2, 0.2))     #creazione dello split con la definizione delle percentuali"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lWne1pMwzq2N",
        "outputId": "610e028e-b363-41a9-997d-db6c3b5feedf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting split-folders\n",
            "  Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\n",
            "Installing collected packages: split-folders\n",
            "Successfully installed split-folders-0.5.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Copying files: 2264 files [00:29, 77.35 files/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# si definisce il wrapping come descritto prima per il dataset di training, mappando il dataset con un dizionario che contiene 'immagine' e 'etichetta'\n",
        "data_dir = 'content/DATASET'\n",
        "\n",
        "#================================================================================================\n",
        "#                                          TRAINING DATASET\n",
        "#================================================================================================\n",
        "\n",
        "torch_train_dataset = {x: datasets.ImageFolder(os.path.join(data_dir, x), transform) for x in ['train', 'val']}\n",
        "train_dataset = FuseDatasetWrapper(name='train', dataset=torch_train_dataset['train'], mapping=('image', 'label'))\n",
        "\n",
        "# si procede a creare il dataset wrappato\n",
        "train_dataset.create()\n",
        "\n",
        "# si definisce il sampler per la creazione dei batch bilanciati di Fuse\n",
        "sampler = FuseSamplerBalancedBatch(dataset=train_dataset,                       #si fornisce in input il dataset da cui creare i batch\n",
        "                                balanced_class_name='data.label',               #si definisce l'etichetta secondo la quale si effettua il bilanciamento\n",
        "                                num_balanced_classes=2,                         #si imposta il numero di classi da bilanciare\n",
        "                                batch_size=train_params['data.batch_size'],     #dimensione del batch, che avendo messo none al parametro di dopo voglio che sia diviso per il num_balanced_classes\n",
        "                                balanced_class_weights=None)                    #mettendo None dico che voglio un numero di classi uguale per ogni batch, altrimenti è un intero \n",
        "                                                                                #che definisce quanti campioni di ogni classe vanno in un batch\n",
        "\n",
        "# Creo il dataloader con la funzione apposita di pytorch\n",
        "train_dataloader = DataLoader(dataset=train_dataset, batch_sampler=sampler, num_workers=train_params['data.train_num_workers'])\n",
        "\n",
        "\n",
        "#================================================================================================\n",
        "#                                         VALIDATION DATASET\n",
        "#================================================================================================\n",
        "\n",
        "\n",
        "# faccio il wrapping con la funzione di fuse\n",
        "validation_dataset = FuseDatasetWrapper(name='validation', dataset=torch_train_dataset['val'], mapping=('image', 'label'))\n",
        "validation_dataset.create()\n",
        "\n",
        "# e creo il dataloader con pytorch\n",
        "validation_dataloader = DataLoader(dataset=validation_dataset, batch_size=train_params['data.batch_size'],\n",
        "                                num_workers=train_params['data.validation_num_workers'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttTnF55AFECv",
        "outputId": "958f9326-583b-45ff-a20f-85dfa2f79c83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Fase di definizione del modello**\n",
        "Si construisce ora la rete VGG11 usando PyTorch e poi se ne fa il wrapping usando le funzioni di Fuse.\n",
        "Il modello di output sarà aggregato in un dizionario chiamato `batch_dict['model.*']`."
      ],
      "metadata": {
        "id": "oGSDIZJnJBLs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models import vgg11\n",
        "\n",
        "torch_model = vgg11(pretrained = True)                                                      #prendo il modello di VGG11 preaddestrata\n",
        "\n",
        "model = FuseModelWrapper(model=torch_model,                                                  #modello di cui si vuole fare il wrapping\n",
        "                        model_inputs=['data.image'],                                         #sequenza di chiavi nel dizionario dei batch da trasferire alla funzione model.forward\n",
        "                        post_forward_processing_function=perform_softmax,                    #si sceglie di effettuare una elaborazione di forwarding di tipo SoftMax, usando la funzione apposita\n",
        "                        model_outputs=['logits.classification', 'output.classification']     #chiavi del dizionario dei batch in cui vado a mettere l'output del modello\n",
        "                        )"
      ],
      "metadata": {
        "id": "lUpqHSTFKF43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "5c3270c3c6884c3db7f38b01de3fff38",
            "b513a36dd4b94961918743bbc6363c14",
            "0fdb873ad7f643718a6c81b0609b0223",
            "9f94a71585db4d7cb26c5a7a7f2fb60c",
            "4d812f7157c04c51a0b7c96127624d74",
            "e62aa23d65c842f3ba5b1ca8c4a13c79",
            "5aca86ea9ab44d879a368e02e3128edf",
            "441385cdc14b4dbbbef9a0150ce4d168",
            "7fc4022727b14eceb01b19c5400f4f86",
            "292625d90de342199985d8231a101587",
            "91a3a978bd68403ba4fb114979bb523e"
          ]
        },
        "outputId": "43ff7c5e-f81c-4c2d-e3f3-bb896daec998"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg11-8a719046.pth\" to /root/.cache/torch/hub/checkpoints/vgg11-8a719046.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/507M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5c3270c3c6884c3db7f38b01de3fff38"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Stampa della conformazione della rete convoluzionale"
      ],
      "metadata": {
        "id": "anC0gSBiRHbH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWeNFWwFRKsb",
        "outputId": "d9b77ec8-0601-4c16-d69a-d1e0b020b55e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): ReLU(inplace=True)\n",
              "    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (9): ReLU(inplace=True)\n",
              "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (12): ReLU(inplace=True)\n",
              "    (13): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (14): ReLU(inplace=True)\n",
              "    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (17): ReLU(inplace=True)\n",
              "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (19): ReLU(inplace=True)\n",
              "    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): Dropout(p=0.5, inplace=False)\n",
              "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Fase di creazione della funzione di Loss**\n",
        "Si crea ora un dizionario di elementi di loss, dove ogni elemento è una classe di tipo FuseLossBase.\n",
        "\n",
        "Il loss totale è calcolato come somma pesata di tutti gli elementi di tale dizionario.\n",
        "\n",
        "L'API Fuse estrae la predizione del modello e l'etichetta dal dizionario e poi applica una funzione di calcolo del loss considerandone i pesi definiti dall'utente."
      ],
      "metadata": {
        "id": "Iu4VsBF4LOlc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "losses = {'cls_loss': FuseLossDefault(pred_name='model.logits.classification',      #si definisce l'etichetta delle predizioni\n",
        "                                      target_name='data.label',                     #si sceglie il nome della colonna target\n",
        "                                      callable=F.cross_entropy,                     #si imposta la funzione di pytorch di calcolo del loss\n",
        "                                      weight=1.0)                                   #valore da moltiplicare ai pesi finali per computare il loss totale\n",
        "                                                                                    #serve per dare un peso maggiore ai loss calcolati mano mano durante il processo\n",
        "}"
      ],
      "metadata": {
        "id": "vk4PuIfrL895"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Fase di definizione delle metriche di addestramento**\n",
        "Si crea un dizionario di elementi, in cui ogni elemento è un metrica definita come oggetto della classe FuseMatricBase.\n",
        "\n",
        "Le metriche sono calcolate per ogni epoca, sia per la validation che per la fase di addestramento.\n",
        "\n",
        "La 'best_epoch_source', serve a salvare il miglior modello ottenuto durante la fase di train basandosi sulle metriche che vengono definite."
      ],
      "metadata": {
        "id": "J1lFfIRoOscw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = OrderedDict([\n",
        "    # definisco la soglia da usare per la classificazione, se impostato così si fa ArgMax, con le probabilità\n",
        "    ('operation_point', MetricApplyThresholds(pred='model.output.classification')),                         #pred: parametro che definisce il nome della chiave nel vettore degli score delle predizioni\n",
        "                                                                                                            #class_names: nomi delle classi. Questo parametro è richiesto se si fa un problema multiclasse\n",
        "    #creo l'oggetto Accuracy\n",
        "    ('accuracy', MetricAccuracy(pred='results:metrics.operation_point.cls_pred',        #chiave delle predizioni da collezionare su cui fare il calcolo\n",
        "                                target='data.label'))                                   #chiave della classe target su cui calcolare l'accuracy\n",
        "])"
      ],
      "metadata": {
        "id": "KU9utFVcPMvY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Fase di creazione degli oggetti Callbacks**\n",
        "Definisco i callbacks come oggetti della classe FuseCallbackBase\n",
        "\n",
        "Un **callback** è un oggetto che fa varie azioni durante i passi del training.\n",
        "\n",
        "Ad ogni step è possibile infatti fare delle manipolazioni dei dati, del dizionario dei batch batch_dict, o dei risultati di ogni epoca epoch_results.\n"
      ],
      "metadata": {
        "id": "3tkpGG3fRPzU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "    FuseTensorboardCallback(model_dir=paths['model_dir']),  # la funzione serve per salvare le statistiche di train e validation in dei file di log di tensor\n",
        "                                                              # detti tensorboard. Devo definire solo il path in cui vengono salvate le cose\n",
        "]"
      ],
      "metadata": {
        "id": "EuMwlzE9RwXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Fase di addestramento della rete**\n",
        "Si va a costruire un manager di Fuse, e si correda tale manager di ottimizzatori e di scheduler presi dalla libreria Pytorch.\n",
        "\n",
        "I possibili workflow da seguire sono nella documentazione della classe FuseManagerDefault.\n",
        "\n",
        "Si nota che il manager usa i parametri di training che abbiamo settato in precedenza."
      ],
      "metadata": {
        "id": "P_Qm6pNQScTi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creo l'ottimizzatore usando Adam, dando in input i parametri del modello, il learning rate e i pesi\n",
        "optimizer = optim.Adam(model.parameters(), lr=train_params['manager.learning_rate'], weight_decay=train_params['manager.weight_decay'])\n",
        "\n",
        "# creo lo scheduler sull'ottimizzatore per ridurre il learning rate quando il modello smette di migliorarsi\n",
        "# lo scheduler vede se l'ottimizzatore migliora, altrimenti abbassa il learing rate e da un miglioramento più fine alla rete\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer)\n",
        "\n",
        "# tdefinisco il Manager di Fuse, per la gestione dei processi di train e di validation. In questo caso si sta facendo un train by scratch\n",
        "manager = FuseManagerDefault(output_model_dir=paths['model_dir'],           #path della directory del modello\n",
        "                             force_reset=paths['force_reset_model_dir'])    #se è True la directory si ripristina in automatico\n",
        "                                                                            #se è False, cioè di default, la directory va resettata manualmente\n",
        "\n",
        "#============================================================================================================================================\n",
        "# I POSSIBILI WORKFLOW DATI DAL MANAGER SONO I SEGUENTI:\n",
        "#\n",
        "#     Per l'addestramento:\n",
        "#         FuseManagerDefault() -> manager.set_objects() -> manager.train()\n",
        "#     Per riprendere l'addestramento da un checkpoint:\n",
        "#         FuseManagerDefault() -> manager.load_objects() -> manager.load_checkpoint() -> manager.train()\n",
        "#     Per l'addestramento partendo da un modello pre-esistente:\n",
        "#         FuseManagerDefault() -> manager.set_objects() [-> manager.load_objects()] [-> manager.load_checkpoint()] -> manager.train()\n",
        "#     Per la fase di inferenza:\n",
        "#         FuseManagerDefault() -> manager.infer()\n",
        "#         or -\n",
        "#         FuseManagerDefault() -> manager.load_objects() -> manager.load_checkpoint() -> manager.infer()\n",
        "#     Per la fase di inferenza dato un modello:\n",
        "#         FuseManagerDefault() -> manager.set_objects() -> manager.load_checkpoint() -> manager.infer()\n",
        "#============================================================================================================================================\n",
        "\n",
        "\n",
        "# Impostiamo il manager per lavorare con gli oggetti che abbiamo creato:\n",
        "manager.set_objects(net=model,                                                      #modello in input\n",
        "                    optimizer=optimizer,                                            #ottimizzatore\n",
        "                    losses=losses,                                                  #definizione delle funzioni di loss  \n",
        "                    metrics=metrics,                                                #dizionario delle metriche da elaborare per ogni batch\n",
        "                    best_epoch_source=train_params['manager.best_epoch_source'],    #metriche usate per decidere la best epoch. Può essere anche una lista che contiene le chiavi:\n",
        "                                                                                    #   'source': nome della metrica di loss- e.g. losses.cls_loss or metrics.auc\n",
        "                                                                                    #   'optimization': l'ottimizzazione da fare sulla metrica, massimizzare o minimizzare.\n",
        "                                                                                    #   'on_equal_values': che cosa fare in caso di valori uguali di epoca, prendere il migliore(best) o il peggiore(worse)\n",
        "                    lr_scheduler=scheduler,                                         #funzione di scheduling\n",
        "                    callbacks=callbacks,                                            #eventuali callback che voglio fare, nel nostro caso salvare i pesi\n",
        "                    train_params=train_params['manager.train_params'])              #set di parametri di training che ho definito in un dizionario prima\n",
        "\n",
        "# FUNZIONE CHE ESEGUE L'ADDESTRAMENTO DELLA RETE PASSANDOGLI IL DATASET DI TRAIN E DI VALIDATION SU CUI CALCOLARE LE METRICHE\n",
        "manager.train(train_dataloader=train_dataloader, validation_dataloader=validation_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-umGUtfS9RJ",
        "outputId": "efbbf55d-18f6-449c-fbfe-cd7b167defaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 7/7 [00:10<00:00,  1.53s/it]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 24/24 [00:23<00:00,  1.00it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 7/7 [00:06<00:00,  1.12it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 24/24 [00:24<00:00,  1.00s/it]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 7/7 [00:06<00:00,  1.11it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 24/24 [00:25<00:00,  1.08s/it]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 7/7 [00:06<00:00,  1.10it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 24/24 [00:24<00:00,  1.01s/it]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 7/7 [00:06<00:00,  1.11it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 24/24 [00:25<00:00,  1.05s/it]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 7/7 [00:06<00:00,  1.10it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 24/24 [00:24<00:00,  1.01s/it]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 7/7 [00:06<00:00,  1.10it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 24/24 [00:24<00:00,  1.01s/it]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 7/7 [00:06<00:00,  1.12it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 24/24 [00:24<00:00,  1.02s/it]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 7/7 [00:06<00:00,  1.13it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 24/24 [00:23<00:00,  1.00it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 7/7 [00:06<00:00,  1.12it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 24/24 [00:24<00:00,  1.02s/it]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 7/7 [00:06<00:00,  1.12it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 24/24 [00:24<00:00,  1.03s/it]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 7/7 [00:06<00:00,  1.04it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 24/24 [00:23<00:00,  1.02it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 7/7 [00:06<00:00,  1.11it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 24/24 [00:25<00:00,  1.04s/it]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 7/7 [00:06<00:00,  1.11it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 24/24 [00:24<00:00,  1.04s/it]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 7/7 [00:06<00:00,  1.13it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 24/24 [00:24<00:00,  1.02s/it]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 7/7 [00:06<00:00,  1.13it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 24/24 [00:24<00:00,  1.04s/it]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 7/7 [00:06<00:00,  1.11it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 24/24 [00:24<00:00,  1.02s/it]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 7/7 [00:06<00:00,  1.12it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 24/24 [00:25<00:00,  1.06s/it]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 7/7 [00:08<00:00,  1.16s/it]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 24/24 [00:24<00:00,  1.04s/it]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 7/7 [00:06<00:00,  1.11it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 24/24 [00:24<00:00,  1.03s/it]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 7/7 [00:06<00:00,  1.14it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 24/24 [00:24<00:00,  1.02s/it]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 7/7 [00:06<00:00,  1.11it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 24/24 [00:24<00:00,  1.02s/it]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 7/7 [00:06<00:00,  1.11it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 24/24 [00:24<00:00,  1.04s/it]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 7/7 [00:06<00:00,  1.12it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 24/24 [00:24<00:00,  1.04s/it]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 7/7 [00:06<00:00,  1.02it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 24/24 [00:24<00:00,  1.02s/it]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 7/7 [00:06<00:00,  1.12it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 24/24 [00:25<00:00,  1.05s/it]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 7/7 [00:06<00:00,  1.12it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 24/24 [00:24<00:00,  1.03s/it]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 7/7 [00:06<00:00,  1.12it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 24/24 [00:24<00:00,  1.01s/it]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 7/7 [00:06<00:00,  1.11it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 24/24 [00:24<00:00,  1.01s/it]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 7/7 [00:06<00:00,  1.12it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 24/24 [00:24<00:00,  1.02s/it]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 7/7 [00:06<00:00,  1.11it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 24/24 [00:24<00:00,  1.04s/it]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 7/7 [00:06<00:00,  1.12it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 24/24 [00:24<00:00,  1.01s/it]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 7/7 [00:06<00:00,  1.13it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 24/24 [00:25<00:00,  1.05s/it]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 7/7 [00:06<00:00,  1.13it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 24/24 [00:24<00:00,  1.00s/it]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 7/7 [00:06<00:00,  1.12it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 24/24 [00:24<00:00,  1.01s/it]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 7/7 [00:06<00:00,  1.13it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 24/24 [00:24<00:00,  1.03s/it]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 7/7 [00:06<00:00,  1.12it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 24/24 [00:24<00:00,  1.02s/it]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 7/7 [00:06<00:00,  1.04it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 24/24 [00:23<00:00,  1.02it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 7/7 [00:06<00:00,  1.13it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 24/24 [00:24<00:00,  1.02s/it]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 7/7 [00:06<00:00,  1.04it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Fase di inferenza**\n",
        "Una volta addestrata la rete, voglio i suoi migliori parametri per testare la rete su un test set locale, per valutare la capacità di generalizzazione della rete stessa."
      ],
      "metadata": {
        "id": "C6Z0kXhPWkgG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Definizione dei parametri di inferenza"
      ],
      "metadata": {
        "id": "gjNJp93tX1kS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "INFER_COMMON_PARAMS = {}\n",
        "INFER_COMMON_PARAMS['infer_filename'] = 'validation_set_infer.gz'\n",
        "INFER_COMMON_PARAMS['checkpoint'] = 'best' \n",
        "\n",
        "\n",
        "infer_common_params = INFER_COMMON_PARAMS"
      ],
      "metadata": {
        "id": "pDPIEJEVX9Ss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Processo di inferenza"
      ],
      "metadata": {
        "id": "5GrzJAQWYAjS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prendo dei pezzi dal validation per fare il test locale\n",
        "torch_test_dataset = {'test': datasets.ImageFolder(os.path.join(data_dir, 'test'), transform)}\n",
        "\n",
        "test_dataset = FuseDatasetWrapper(name='test', dataset=torch_test_dataset['test'], mapping=('image', 'label'))\n",
        "# si procede a creare il dataset wrappato\n",
        "test_dataset.create()\n",
        "\n",
        "test_dataloader = DataLoader(dataset=test_dataset, collate_fn=test_dataset.collate_fn, batch_size=2, num_workers=2)\n",
        "\n",
        "# creo un manager Fuse per fare le operazioni di inferenza\n",
        "manager = FuseManagerDefault()\n",
        "# definisco le colonne che mi servono per l'output\n",
        "output_columns = ['model.output.classification', 'data.label']\n",
        "\n",
        "# FUNZIONE CHE ESEGUE IL PROCESSO DI INFERENZA SUI DATI\n",
        "manager.infer(data_loader=test_dataloader,                                                                #definizione del dataset di inferenza\n",
        "                input_model_dir=paths['model_dir'],                                                             #path del modello da dove devo prendere i dati\n",
        "                checkpoint=infer_common_params['checkpoint'],                                                   #definisco da dove devo prendere i pesi della rete\n",
        "                output_columns=output_columns,                                                                  #scelgo le colonne che devo restituire in output\n",
        "                output_file_name=os.path.join(paths[\"inference_dir\"], infer_common_params[\"infer_filename\"]))   #path dove vanno a finire gli output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "LO9eQdrlYF-n",
        "outputId": "ceb3bee0-8b37-449b-a42d-748a4c013790"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 227/227 [00:06<00:00, 32.52it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      descriptor           id  \\\n",
              "0      (test, 0)    (test, 0)   \n",
              "1      (test, 1)    (test, 1)   \n",
              "2      (test, 2)    (test, 2)   \n",
              "3      (test, 3)    (test, 3)   \n",
              "4      (test, 4)    (test, 4)   \n",
              "..           ...          ...   \n",
              "449  (test, 449)  (test, 449)   \n",
              "450  (test, 450)  (test, 450)   \n",
              "451  (test, 451)  (test, 451)   \n",
              "452  (test, 452)  (test, 452)   \n",
              "453  (test, 453)  (test, 453)   \n",
              "\n",
              "                           model.output.classification  data.label  \n",
              "0    [0.99999917, 2.1591481e-07, 2.3864287e-11, 2.2...           0  \n",
              "1    [0.9999995, 2.2115915e-07, 9.6838666e-12, 9.01...           0  \n",
              "2    [0.9999999, 3.23253e-08, 1.5215458e-12, 1.4138...           0  \n",
              "3    [0.99999607, 3.1012526e-06, 5.3519227e-11, 4.5...           0  \n",
              "4    [0.9999765, 2.1153464e-05, 1.919223e-10, 1.655...           0  \n",
              "..                                                 ...         ...  \n",
              "449  [1.4600917e-06, 0.99999845, 1.2417709e-10, 9.4...           1  \n",
              "450  [1.0245627e-05, 0.99998975, 4.740749e-12, 4.04...           1  \n",
              "451  [0.000512005, 0.999488, 1.5353308e-12, 1.16443...           1  \n",
              "452  [3.101214e-06, 0.9999969, 2.7139688e-11, 1.885...           1  \n",
              "453  [5.1900224e-05, 0.9999453, 3.6833243e-09, 2.97...           1  \n",
              "\n",
              "[454 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1ed8a1dd-89fe-487c-a3e1-bb743e0493d2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>descriptor</th>\n",
              "      <th>id</th>\n",
              "      <th>model.output.classification</th>\n",
              "      <th>data.label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>(test, 0)</td>\n",
              "      <td>(test, 0)</td>\n",
              "      <td>[0.99999917, 2.1591481e-07, 2.3864287e-11, 2.2...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>(test, 1)</td>\n",
              "      <td>(test, 1)</td>\n",
              "      <td>[0.9999995, 2.2115915e-07, 9.6838666e-12, 9.01...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>(test, 2)</td>\n",
              "      <td>(test, 2)</td>\n",
              "      <td>[0.9999999, 3.23253e-08, 1.5215458e-12, 1.4138...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>(test, 3)</td>\n",
              "      <td>(test, 3)</td>\n",
              "      <td>[0.99999607, 3.1012526e-06, 5.3519227e-11, 4.5...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>(test, 4)</td>\n",
              "      <td>(test, 4)</td>\n",
              "      <td>[0.9999765, 2.1153464e-05, 1.919223e-10, 1.655...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>449</th>\n",
              "      <td>(test, 449)</td>\n",
              "      <td>(test, 449)</td>\n",
              "      <td>[1.4600917e-06, 0.99999845, 1.2417709e-10, 9.4...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>450</th>\n",
              "      <td>(test, 450)</td>\n",
              "      <td>(test, 450)</td>\n",
              "      <td>[1.0245627e-05, 0.99998975, 4.740749e-12, 4.04...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>451</th>\n",
              "      <td>(test, 451)</td>\n",
              "      <td>(test, 451)</td>\n",
              "      <td>[0.000512005, 0.999488, 1.5353308e-12, 1.16443...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>452</th>\n",
              "      <td>(test, 452)</td>\n",
              "      <td>(test, 452)</td>\n",
              "      <td>[3.101214e-06, 0.9999969, 2.7139688e-11, 1.885...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>453</th>\n",
              "      <td>(test, 453)</td>\n",
              "      <td>(test, 453)</td>\n",
              "      <td>[5.1900224e-05, 0.9999453, 3.6833243e-09, 2.97...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>454 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1ed8a1dd-89fe-487c-a3e1-bb743e0493d2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1ed8a1dd-89fe-487c-a3e1-bb743e0493d2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1ed8a1dd-89fe-487c-a3e1-bb743e0493d2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Fase di valutazione delle performance**\n",
        "Uso la classe Evaluator per la valutazione delle performance. Non è necessario che il modello sia di Fuse per usare questa classe.\n"
      ],
      "metadata": {
        "id": "ui0T0JaYc7FF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Definizione dei parametri di valutazione"
      ],
      "metadata": {
        "id": "o9wk_fq7duiF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EVAL_COMMON_PARAMS = {}\n",
        "EVAL_COMMON_PARAMS['infer_filename'] = INFER_COMMON_PARAMS['infer_filename']\n",
        "eval_common_params = EVAL_COMMON_PARAMS"
      ],
      "metadata": {
        "id": "P0NhA9OFdpSG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Definizione delle metriche di valutazione"
      ],
      "metadata": {
        "id": "N3UNAlifdyui"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# definisco le classi su cui calcolare le metriche\n",
        "\n",
        "class_names = ['volGBM', 'volMET']\n",
        "\n",
        "# Definizione delle metriche come dizionario\n",
        "metrics = OrderedDict([\n",
        "    ('operation_point', MetricApplyThresholds(pred='model.output.classification')), # come fatto in precedenza si applica ArgMax\n",
        "    ('accuracy', MetricAccuracy(pred='results:metrics.operation_point.cls_pred', target='data.label')), # definizione dell'accuracy come classe , come fatto prima\n",
        "    ('roc', MetricROCCurve(pred='model.output.classification',          #creo una curva ROC per la valutazione e la salvo in un immagine\n",
        "                           target='data.label', \n",
        "                           class_names=class_names, \n",
        "                           output_filename=os.path.join(paths['inference_dir'], 'roc_curve.png'))), \n",
        "    ('auc', MetricAUCROC(pred='model.output.classification',        # definisco la metrica AUC sulla cuva ROC\n",
        "                         target='data.label', \n",
        "                         class_names=class_names)),\n",
        "    ('aucpr', MetricAUCPR(pred='model.output.classification',\n",
        "                                  target='data.label',\n",
        "                                  class_names=class_names)),\n",
        "    ('brier-skill', MetricBSS(pred='model.output.classification',\n",
        "                                  target='data.label'))\n",
        "])"
      ],
      "metadata": {
        "id": "KGfBW0k_d27D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Processo di valutazione e visualizzazione dei risultati"
      ],
      "metadata": {
        "id": "caX8lwrWd3VI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creo la classe Evaluator\n",
        "evaluator = EvaluatorDefault()\n",
        "\n",
        "# FUNZIONE CHE ESEGUE IL PROCESSO DI EVALUATION SUI DATI\n",
        "results = evaluator.eval(ids=None,\n",
        "                data=os.path.join(paths[\"inference_dir\"], eval_common_params[\"infer_filename\"]),\n",
        "                metrics=metrics,\n",
        "                output_dir=paths['eval_dir'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQCIAoERd360",
        "outputId": "6822cd2e-de73-4cd1-ff95-72c1a98d5696"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results:\n",
            "\n",
            "Metric operation_point:\n",
            "------------------------------------------------\n",
            "cls_pred:\n",
            "<fuse.eval.metrics.utils.PerSampleData object at 0x7f3b72697850>\n",
            "\n",
            "Metric accuracy:\n",
            "------------------------------------------------\n",
            "0.9537444933920705\n",
            "\n",
            "Metric roc:\n",
            "------------------------------------------------\n",
            "volGBM.fpr:\n",
            "[0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.00552486 0.00552486\n",
            " 0.00552486 0.00552486 0.01104972 0.01104972 0.01657459 0.01657459\n",
            " 0.02209945 0.02209945 0.02762431 0.02762431 0.03314917 0.03314917\n",
            " 0.0441989  0.0441989  0.04972376 0.04972376 0.06077348 0.06077348\n",
            " 0.06629834 0.06629834 0.0718232  0.0718232  0.08287293 0.08287293\n",
            " 0.09392265 0.09392265 0.09944751 0.09944751 0.11049724 0.11049724\n",
            " 0.12707182 0.12707182 0.14364641 0.14364641 0.15469613 0.15469613\n",
            " 0.68508287 0.6961326  1.        ]\n",
            "volGBM.tpr:\n",
            "[0.         0.16849817 0.25274725 0.2967033  0.33333333 0.37728938\n",
            " 0.3956044  0.41025641 0.41758242 0.44322344 0.45787546 0.47985348\n",
            " 0.49084249 0.50915751 0.52380952 0.53846154 0.54212454 0.56410256\n",
            " 0.57142857 0.58608059 0.60805861 0.61904762 0.62637363 0.63003663\n",
            " 0.63736264 0.64835165 0.65567766 0.67032967 0.67032967 0.68498168\n",
            " 0.69230769 0.73992674 0.73992674 0.78021978 0.78021978 0.8974359\n",
            " 0.8974359  0.91575092 0.91575092 0.91941392 0.91941392 0.92673993\n",
            " 0.92673993 0.94505495 0.94505495 0.95970696 0.95970696 0.96336996\n",
            " 0.96336996 0.96703297 0.96703297 0.97069597 0.97069597 0.97435897\n",
            " 0.97435897 0.98168498 0.98168498 0.98534799 0.98534799 0.98901099\n",
            " 0.98901099 0.99267399 0.99267399 0.996337   0.996337   1.\n",
            " 1.         1.         1.        ]\n",
            "volGBM.auc:\n",
            "0.9908930848157367\n",
            "volMET.fpr:\n",
            "[0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.003663   0.003663   0.00732601 0.00732601 0.01098901 0.01098901\n",
            " 0.01465201 0.01465201 0.01831502 0.01831502 0.02564103 0.02564103\n",
            " 0.02930403 0.02930403 0.03296703 0.03296703 0.03663004 0.03663004\n",
            " 0.04029304 0.04029304 0.05494505 0.05494505 0.07326007 0.07326007\n",
            " 0.08058608 0.08058608 0.08424908 0.08424908 0.1025641  0.1025641\n",
            " 0.21611722 0.21611722 0.26007326 0.26007326 0.34432234 0.34432234\n",
            " 1.        ]\n",
            "volMET.tpr:\n",
            "[0.         0.1878453  0.26519337 0.27071823 0.28729282 0.29281768\n",
            " 0.31491713 0.32044199 0.34254144 0.37569061 0.38674033 0.40883978\n",
            " 0.42541436 0.43093923 0.44198895 0.45303867 0.47513812 0.49171271\n",
            " 0.50276243 0.51381215 0.52486188 0.58563536 0.59668508 0.84530387\n",
            " 0.84530387 0.85635359 0.85635359 0.87292818 0.87292818 0.88950276\n",
            " 0.88950276 0.90055249 0.90055249 0.90607735 0.90607735 0.91712707\n",
            " 0.91712707 0.9281768  0.9281768  0.93370166 0.93370166 0.93922652\n",
            " 0.93922652 0.95027624 0.95027624 0.9558011  0.9558011  0.96685083\n",
            " 0.96685083 0.97237569 0.97237569 0.97790055 0.97790055 0.98342541\n",
            " 0.98342541 0.98895028 0.98895028 0.99447514 0.99447514 1.\n",
            " 1.        ]\n",
            "volMET.auc:\n",
            "0.9908323720478417\n",
            "\n",
            "Metric auc:\n",
            "------------------------------------------------\n",
            "volGBM:\n",
            "0.9908930848157367\n",
            "volMET:\n",
            "0.9908323720478417\n",
            "macro_avg:\n",
            "0.9908627284317892\n",
            "\n",
            "Metric aucpr:\n",
            "------------------------------------------------\n",
            "volGBM:\n",
            "0.9936129096208871\n",
            "volMET:\n",
            "0.9883560218639798\n",
            "macro_avg:\n",
            "0.9909844657424334\n",
            "\n",
            "Metric brier-skill:\n",
            "------------------------------------------------\n",
            "0.8305695615278346\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Brier-Skill Score"
      ],
      "metadata": {
        "id": "Lie5JDQ_whF3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "L'**indice di Brier** indica la percentuale di incertezza del classificatore. E' un valore tra 0 e 1, e più vicino a zero è più è bassa l'incertezza del classificatore.\n",
        "La metrica che calcola Fuse è invece il complemento a 1 della percentuale dell'indice di brier, e quindi più è alto il **punteggio Brier-Skill**, minore sarà l'incertezza del classificatore.\n",
        "\n",
        "Praticamente sto calcolando lo scarto quadratico medio delle predizioni. "
      ],
      "metadata": {
        "id": "HWGy4CR7t393"
      }
    }
  ]
}